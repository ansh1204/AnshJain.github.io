<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ansh</title>
  
  <meta name="author" content="Ansh Jain">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:0.0%;width:63%;vertical-align:middle">
                <p style="text-align:center;font-size:2.5vw">
                <name><b>Ansh Jain</b></name>
            </p>
              
              <p>I am a student at University of Wisconsin Madison, pursuing Master's in Computer Science. My courses included
                <ul>
                  <li>Fall 2021 - CS 760 Machine Learning, CS 532 Matrix methods in Machine learning, CS 764 Topics in DBMS</li>
                  <li>Spring 2022 - CS 639 Foundations of Data Science, CS 739 Distributed Systems, CS 766 Computer Vision</li>
                </ul>
              I completed my Bachelor's degree from Netaji Subhas Institute of Technology, Delhi University (currently Netaji Subhas University of Technology) in Information Technology. Afterwards, I worked at the Samsung R&D Institute India, Bangalore (SRIB) for 2 years before my Master's. 
              </p>
              <p> Previously, my research work has been majorly in the field of Machine Learning, Computer Vision and NLP. Additionally, I have development experience with samsung where I worked 
                on Samsung's video editor engine. I am also interested in the systems field, which I am exploring at UW Madison as a graduate student. My enthusiasm for learning is unceasing and I hope to continue creating an impact in the Computer Science field.
              <p style="text-align:center">
                <a href="mailTo:jain98@wisc.edu">Email</a> &nbsp/&nbsp
                <a href="data/Resume_Ansh.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=P7_uLR8AAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ansh1204">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="Data/profile_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="Data/profile_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:0px;width:100%;vertical-align:middle">
            <p style="font-size:2vw">
            <heading>Experience</heading>
          </p>
          </td>
        </tr>
      </tbody></table>
      <table class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src='Data/Samsung_Logo.png' width="160">
                </div>
            </td>
            <td style="padding:10px;width:75%;vertical-align:top">
                <papertitle style="color:gray"> <big>Senior Software Engineer</big> </papertitle> <papertitle ><big> | Samsung RnD Institute Bangalore</big></papertitle>
                <br>
                June '19 - July'21
                <br>
                <p> At Samsung I worked in the Video Editor team and was fortunate to contribute to the application. The majority of my time at Samsung was 
                  spent working on the Video Classification project, and the remaining time I worked on the development of video editing features such as 360 
                  video editing, tone filters, video highlight creation, etc. In addition to that, I was the main contributor from our team to the Single Take feature, 
                  which was the USP of Samsung S21 and presented at the launch event.
                </p>
            </td>
        </tr>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:right; text-align: center;">
              <div class="one">
                  <img src='Data/IITK_Logo.png' width="120">
              </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">
              <papertitle style="color:gray"> <big>Researcher</big> </papertitle> <papertitle ><big> | Indian Institute of Technology Kanpur</big></papertitle>
              <br>
              December '18 - March'19, Jan'20 - June'20
              <br>
              <p>I worked full-time for the first two months and remotely part-time for the remaining time with the Computer Vision and Language lab. 
                The project initially started as an improvement of the state-of-the-art for Visual Question Answering (VQA) but later evolved 
                into a general approach to improve attention networks in deep learning networks thus increasing their accuracy. The research work was published 
                in one of the top conferences in computer vision, WACV.
              </p>
          </td>
      </tr>

      <tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='Data/Samsung_Logo.png' width="160">
            </div>
        </td>
        <td style="padding:10px;width:75%;vertical-align:top">
            <papertitle style="color:gray"> <big>Software Development Intern</big> </papertitle> <papertitle ><big> | Samsung RnD Institute Bangalore</big></papertitle>
            <br>
            May '18 - July'18
            <br>
            <p>The two-month internship was challenging and helped me develop an understanding of how an industry works. 
              During the course of my project, I created a GUI with a backend for Lightweight Machine-to-Machine (LWM2M) device management
               for IoT devices working on Constrained Application Protocol (CoAP) using the Java Swing framework in Eclipse. In addition to that, I was among
                the top 3% of interns to clear the advanced level coding test based on data structures and algorithms on the first attempt.
            </p>
        </td>
    </tr>
      
      </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0 0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <p style="font-size:2vw">
              <heading>Research and Publications</heading>
            </p>
            </td>
          </tr>
        </tbody></table><!----><table style="width:100%;border:0px;border-spacing:0 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/Self_Supervision.png"><img style="width:100%;max-width:100%" alt="Self Supervision" src="Data/Self_Supervision.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Patro_Self_Supervision_for_Attention_Networks_WACV_2021_paper.pdf">
                <papertitle>Self Supervision for Attention Networks</papertitle>
              </a>
              <br>
              <strong>Ansh Jain*</strong>,
              <a> Badri N Patro*</a>,
              <a> Kasturi GS*</a>,
              <a> Vinay P Namboodiri</a>
              <br>
							<em>(*equal contribution)</em>, Winter Conference on Applications of Computer Vision (WACV) 2021
              <br>
              
              <p>In this paper, we propose a novel method to improve the attention mechanism by inducing “self-supervision”. The method introduced
                in this paper can be generalized to deep learning model that utilizes an attention module. It can be extended to different input modalities like text and image.
              <br>
              <a style="text-decoration:none" href="http://github.com/ansh1204/Self_Supervsion_for_Attention_Networks">[Code]</a>
              |
              <a style="text-decoration:none" href="https://sites.google.com/view/visionandlanguage/part1">[Initial Research]</a>
              </p>
            </td>
          </tr> 
          

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/RFJamming.png"><img style="width:100%;max-width:100%" alt="RF Jamming" src="Data/RFJamming.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="http://isyou.info/jowua/papers/jowua-v11n4-4.pdf">
                <papertitle>Detection and Classification of Radio Frequency Jamming Attacks using Machine learning</papertitle>
              </a>
              <br>
              <a> Kasturi GS*</a>
              <a>Ansh Jain*</a>,
              <a> Jagdeep Singh*</a>
              <br>
							<em>(*equal contribution)</em>, JoWUA Vol. 11, No. 4 journal 2020
              <br>
              
              <p> In this project, we explore the detection and classification Radio Frequency Jamming attacks in wireless ad-hoc networks. This is necessary
                to take appropraite countermeasures against different type of attacks and prevent them.
                <br>
                <a style="text-decoration:none" href="https://github.com/ansh1204/RF_Jamming_Classification">[Code]</a>
              </p>
            </td>
          </tr> 


          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/gcn_model.jpg"><img style="width:100%;max-width:100%" alt="GCN Model" src="Data/gcn_model.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
                <papertitle><u>Paraphrase Question Generation Through Graph Convolution Network</u></papertitle>
              <br>
              <a>Ansh Jain</a>,
              <a>Kasturi GS</a>,
              <a>Badri N Patro</a>
              <br>
              <br>
              
              <p> In this project, we propose an encoder-decoder model to create a better sentence level embedding and evaluate the model on the task of Paraphrase Question
              generation. The semantics are captured by a pairwise decoder that enforces encodings of similar sentences to be close to each other. Further, the syntactics
              of sentences are captured by stacking a GCN over LSTM states.  
              <br>
              <a style="text-decoration:none" href="https://github.com/ansh1204/RF_Jamming_Classification">[Code]</a>
            </td>
          </tr> 

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <p style="font-size:2vw">
                <heading>Other Projects</heading>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/ImageTranslation.png"><img style="width:100%;max-width:100%" alt="Image Translation" src="Data/ImageTranslation.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://github.com/ansh1204/Image_to_Image_Translation_GAN/blob/main/Project_Report.pdf">
                <papertitle>Developing GAN for Image-to-Image-Translation</papertitle>
              </a>
              <br>
              <a>Ansh Jain</a>,
              <a> Kaushal Rai</a>
              <br>
							<em>CS:760 Machine Learning: Course Project</em>
              <br>
              
              <p> We analyze the hypothesis that generative models trained through adversarial process achieve appreciable results on Image-to-Image Translation tasks. 
                For this purpose, we develop a GAN and train it on the "maps" dataset from pix2pix. We further compare the developed model with a style transfer 
                architecture and present the results.
                <br>
                <a style="text-decoration:none" href="https://github.com/ansh1204/Image_to_Image_Translation_GAN">[Code]</a>
              </p>
            </td>
          </tr> 
 

        </tbody></table>

				
    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p>
                The source code for the website can be found <a href="https://github.com/ansh1204/ansh1204.github.io">here</a>. This is a modification of the template
                by <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>