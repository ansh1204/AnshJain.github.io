<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ansh</title>
  
  <meta name="author" content="Ansh Jain">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:0.0%;width:63%;vertical-align:middle">
                <p style="text-align:center;font-size:2.5vw">
                <name><b>Ansh Jain</b></name>
            </p>
              
              <p> I am currently working at Amazon as an Applied Scientist. My team is responsible for predicting, identifying and mitigating risks that a product or service might face when launched.
                <br>Prior to Amazon, I graduated from the University of Wisconsin Madison, with a Master's in Computer Science. During my time, I also worked with Prof. Mohit Gupta in the domain of efficient
                video understanding. My courses included:-
                <ul>
                  <li>Fall 2021 - CS 760 Machine Learning, CS 532 Matrix methods in Machine learning, CS 764 Topics in DBMS</li>
                  <li>Spring 2022 - CS 769 Advanced NLP, CS 839 Deep Learning for Visual Recognition</li>
                  <li>Fall 2022 - CS 561 Probability and information theory in ML, CS 537 Operating System, CS 759 High Performance Computing</li>
                </ul>
              I completed my Bachelor's degree from the Netaji Subhas Institute of Technology, Delhi University (currently Netaji Subhas University of Technology) in Information Technology. Afterward, I worked at the Samsung R&D Institute India, Bangalore (SRIB) for 2 years as a software developer.
              My work focused on on-device video analytics such as video classification for incorporating in Samsung's video editor engine. I further contributed to the development of features such as 360 video editing, video summarization, single take, video filters, etc.
              </p>
              <p> Previously, my research work has been majorly in the field of Machine Learning, Computer Vision, and NLP. I worked with Prof. Vinay P. Namboodiri in the Vision and Language lab at IIT, Kanpur on the topics of attention, multi-modal question answering, and machine translation.
               </p> 
                
                The experiences and learnings have motivated me to continue working in the field and explore more topics in-depth as a graduate student at UWM.
                My enthusiasm for learning is unceasing and I hope to continue creating an impact in the Computer Science field.
              <p style="text-align:center">
                <a href="mailTo:jain98@wisc.edu">Email</a> &nbsp/&nbsp
                <a href="Data/Resume_Ansh.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=P7_uLR8AAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ansh1204">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="Data/profile_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="Data/profile_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:0px;width:100%;vertical-align:middle">
            <p style="font-size:2vw">
            <heading>Experience</heading>
          </p>
          </td>
        </tr>
      </tbody></table>
      <table class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='Data/Amazon-Logo.png' width="160">
              </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">
              <papertitle style="color:gray"> <big>Applied Scientist</big> </papertitle> <papertitle ><big> | Amazon (Amazon.com) </big></papertitle>
              <br>
              Jan'23 - present
              <br>
              <p> 
                Working on the project to improve features/services/products accross amazon wrt to sustainability. The goal is to develop CV algorithms for architecture diagram understanding and recommending better architectural alternatives.
              </p>
          </td>
      </tr>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='Data/amazonLab126.png' width="160">
              </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">
              <papertitle style="color:gray"> <big>Applied Science Intern</big> </papertitle> <papertitle ><big> | Amazon (Amazon Lab126) </big></papertitle>
              <br>
              May '22 - Aug'22
              <br>
              <p> As part of the Halo Health CV team, my project included 3D shape and pose estimation from 2D images. The research project involved implementation of
                techniques for accurate prediction of 3D shape and pose for unconstrained 2D image input in Pytorch. I worked with state-of-the-art models such as SMPL, SMPL-X and
                gained experience with 3D geometry concepts such as human mesh, perspective projection, camera intrinsics etc. 
              </p>
          </td>
      </tr>

        <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src='Data/Samsung_Logo.png' width="160">
                </div>
            </td>
            <td style="padding:10px;width:75%;vertical-align:top">
                <papertitle style="color:gray"> <big>Senior Software Engineer</big> </papertitle> <papertitle ><big> | Samsung RnD Institute Bangalore</big></papertitle>
                <br>
                June '19 - July'21
                <br>
                <p> At Samsung I worked in the Video Editor team and was fortunate to contribute to the application. The majority of my time at Samsung was spent 
                  working on the Video Classification project, where I gained experience in Pytorch, Tensorflow, Keras, Video processing etc. Also, I worked with 
                  state-of-the-art models such as MobileNets, Inception Nets etc. The remaining time I worked on the development of video editing features such as 
                  360 video editing, tone filters, video highlight creation, etc. In addition to that, I was the main contributor from our team to the Single Take 
                  feature, which was the USP of Samsung S21 and presented at the launch event.
                </p>
            </td>
        </tr>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:right; text-align: center;">
              <div class="one">
                  <img src='Data/IITK_Logo.png' width="120">
              </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">
              <papertitle style="color:gray"> <big>Researcher</big> </papertitle> <papertitle ><big> | Indian Institute of Technology Kanpur</big></papertitle>
              <br>
              December '18 - March'19, Jan'20 - June'20
              <br>
              <p>I worked full-time for the first two months and remotely part-time for the remaining time with the Computer Vision and Language lab. 
                The project initially started as an improvement of the state-of-the-art for Visual Question Answering (VQA) but later evolved 
                into a general approach to improve attention networks in deep learning networks thus increasing their accuracy. The research work was published 
                in one of the top conferences in computer vision, WACV.
              </p>
          </td>
      </tr>

      <tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='Data/Samsung_Logo.png' width="160">
            </div>
        </td>
        <td style="padding:10px;width:75%;vertical-align:top">
            <papertitle style="color:gray"> <big>Software Development Intern</big> </papertitle> <papertitle ><big> | Samsung RnD Institute Bangalore</big></papertitle>
            <br>
            May '18 - July'18
            <br>
            <p>The two-month internship was challenging and helped me develop an understanding of how an industry works. 
              During the course of my project, I created a GUI with a backend for Lightweight Machine-to-Machine (LWM2M) device management
               for IoT devices working on Constrained Application Protocol (CoAP) using the Java Swing framework in Eclipse. In addition to that, I was among
                the top 3% of interns to clear the advanced level coding test based on data structures and algorithms on the first attempt.
            </p>
        </td>
    </tr>
      
      </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0 0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <p style="font-size:2vw">
              <heading>Research and Publications</heading>
            </p>
            </td>
          </tr>
        </tbody></table><!----><table style="width:100%;border:0px;border-spacing:0 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/Self_Supervision.png"><img style="width:100%;max-width:100%" alt="Self Supervision" src="Data/Self_Supervision.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Patro_Self_Supervision_for_Attention_Networks_WACV_2021_paper.pdf">
                <papertitle>Self Supervision for Attention Networks</papertitle>
              </a>
              <br>
              <strong>Ansh Jain*</strong>,
              <a> Badri N Patro*</a>,
              <a> Kasturi GS*</a>,
              <a> Vinay P Namboodiri</a>
              <br>
							<em>(*equal contribution)</em>, Winter Conference on Applications of Computer Vision (WACV) 2021
              <br>
              
              <p>In this paper, we propose a novel method to improve the attention mechanism by inducing “self-supervision”. The method introduced
                in this paper can be generalized to deep learning model that utilizes an attention module. It can be extended to different input modalities like text and image.
              <br>
              <a style="text-decoration:none" href="http://github.com/ansh1204/Self_Supervsion_for_Attention_Networks">[Code]</a>
              |
              <a style="text-decoration:none" href="https://sites.google.com/view/visionandlanguage/part1">[Initial Research]</a>
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/active-learning.jpg"><img style="width:100%;max-width:100%" alt="Image Translation" src="Data/active-learning.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="Data/SCALe.pdf">
                <papertitle>SCALe: Supervised Contrastive approach for Active Learning</papertitle>
              </a>
              <br>
              <a>Hardik Chauhan, Ansh Jain, Kaushal Rai, Ritu Raut</a>
              <br>
							<em>CS:769 Advanced NLP</em>
              <br>
              
              <p> The Active Learning approached in NLP use Masked Language Modeling for tasks such as text classification. In this research work, we showcase that this 
                approach has many limitations and that a supervised Contrastive training procedure provides much more intuitive results. We succesfully achieve an improvement
                over SOTA with only a fraction of training data using the proposed techique.

                <br>
                <a style="text-decoration:none" href="https://github.com/kaushalrai7797/SCALe-Supervised-Contrastive-approach-for-Active-Learning">[Code]</a>
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/RFJamming.png"><img style="width:100%;max-width:100%" alt="RF Jamming" src="Data/RFJamming.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="http://isyou.info/jowua/papers/jowua-v11n4-4.pdf">
                <papertitle>Detection and Classification of Radio Frequency Jamming Attacks using Machine learning</papertitle>
              </a>
              <br>
              <a> Kasturi GS*</a>
              <a>Ansh Jain*</a>,
              <a> Jagdeep Singh*</a>
              <br>
							<em>(*equal contribution)</em>, JoWUA Vol. 11, No. 4 journal 2020
              <br>
              
              <p> In this project, we explore the detection and classification Radio Frequency Jamming attacks in wireless ad-hoc networks. This is necessary
                to take appropraite countermeasures against different type of attacks and prevent them.
                <br>
                <a style="text-decoration:none" href="https://github.com/ansh1204/RF_Jamming_Classification">[Code]</a>
              </p>
            </td>
          </tr> 


          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/gcn_model.jpg"><img style="width:100%;max-width:100%" alt="GCN Model" src="Data/gcn_model.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
                <papertitle><u>Paraphrase Question Generation Through Graph Convolution Network</u></papertitle>
              <br>
              <a>Ansh Jain</a>,
              <a>Kasturi GS</a>,
              <a>Badri N Patro</a>
              <br>
              <br>
              
              <p> In this project, we propose an encoder-decoder model to create a better sentence level embedding and evaluate the model on the task of Paraphrase Question
              generation. The semantics are captured by a pairwise decoder that enforces encodings of similar sentences to be close to each other. Further, the syntactics
              of sentences are captured by stacking a GCN over LSTM states.  
              <br>
              <a style="text-decoration:none" href="https://github.com/ansh1204/RF_Jamming_Classification">[Code]</a>
            </td>
          </tr> 
          

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <p style="font-size:2vw">
                <heading>Other Projects</heading>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  
          

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/EvNet.png"><img style="width:100%;max-width:100%" alt="Image Translation" src="Data/EvNet.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2112.00891.pdf">
                <papertitle>Event Neural Network implementation</papertitle>
              </a>
              <br>
              <a>Ansh Jain</a>
              <br>
							<em>CS:799 Master's Research</em>
              <br>
              
              <p> This work was focused on developing the comparison between a traditional and an event-based neural network to
                evaluate the practical computational savings. The aim is to evaluate how the actual savings measure against the theoretical 
                claims of the paper. The code is developed in C++(for vgg16) from scratch with basic data structures as the concepts of the paper
                cannot be tested with standard deep learning frameworks and libraries.

                <br>
                <a style="text-decoration:none" href="https://github.com/ansh1204/Event_nn_CPP">[Code]</a>
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/Object_Removal.png"><img style="width:100%;max-width:100%" alt="Image Translation" src="Data/Object_Removal.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="Data/ObjectRemovalReport.pdf">
                <papertitle>Context Associated Object Removal from Images</papertitle>
              </a>
              <br>
              <a>Ansh Jain, Kaushal Rai, Avinash Kumar, Kriti Goyal</a>
              <br>
							<em>CS 839: Deep Learning for Visual Recognition</em>
              <br>
              
              <p> The goal of the project was to create an end-to-end pipeline to remove unwanted objects from an image, to create a semantically coherent output. Therefore,
                along with objects, it's corresponding context (shadow in our case) also needs to be removed. We combined multiple modules to achieve this, including
                object and shadow segmentation, superpixel creation to fine-tune the segmentation output, and inpainting using a generative model.

                <br>
              
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/ImageTranslation.png"><img style="width:100%;max-width:100%" alt="Image Translation" src="Data/ImageTranslation.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://github.com/ansh1204/Image_to_Image_Translation_GAN/blob/main/Project_Report.pdf">
                <papertitle>Developing GAN for Image-to-Image-Translation</papertitle>
              </a>
              <br>
              <a>Ansh Jain</a>,
              <a> Kaushal Rai</a>
              <br>
							<em>CS:760 Machine Learning: Course Project</em>
              <br>
              
              <p> We analyze the hypothesis that generative models trained through adversarial process achieve appreciable results on Image-to-Image Translation tasks. 
                For this purpose, we develop a GAN and train it on the "maps" dataset from pix2pix. We further compare the developed model with a style transfer 
                architecture and present the results.
                <br>
                <a style="text-decoration:none" href="https://github.com/ansh1204/Image_to_Image_Translation_GAN">[Code]</a>
              </p>
            </td>
          </tr> 


          <tr>
            <td style="padding:10px;width:35%">
              <a href="Data/Query_Structure.png"><img style="width:100%;max-width:100%" alt="Image Translation" src="Data/Query_Structure.png" class="hoverZoomLink"></a>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://github.com/kaushalrai7797/Machine-Learning-Approach-Towards-Predicting-Query-Response-Time/blob/main/Report%20-%20Predicting%20Query%20Response%20Time%20Through%20Machine%20Learning%20Approaches.pdf">
                <papertitle>Intelligent Query Response Time Prediction</papertitle>
              </a>
              <br>
              <a>Ansh Jain</a>,
              <a> Kaushal Rai</a>
              <br>
							<em>CS:764 Topics in DBMS: Course Project</em>
              <br>
              
              <p> The aim of project is to apply supervised learning algorithms for predicting query response time. We develop operator-level
                query predictors for some of the most common database operations. The operator-level models, are easier to train and can generalize
                well to unseen queries.

                <br>
                <a style="text-decoration:none" href="https://github.com/kaushalrai7797/Machine-Learning-Approach-Towards-Predicting-Query-Response-Time">[Code]</a>
              </p>
            </td>
          </tr> 

        </tbody></table>

				
    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p>
                The source code for the website can be found <a href="https://github.com/ansh1204/ansh1204.github.io">here</a>. This is a modification of the template
                by <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
